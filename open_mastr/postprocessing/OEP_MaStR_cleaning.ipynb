{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://openenergy-platform.org/static/OEP_logo_2_no_text.svg\" alt=\"OpenEnergy Platform\" height=\"100\" width=\"100\"  align=\"left\"/>\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/a/ad/Bhl_neue_wege_logo_transparent.svg/2000px-Bhl_neue_wege_logo_transparent.svg.png\" alt=\"BHL\" height=\"300\" width=\"300\" align=\"right\"/>\n",
    "\n",
    "# OpenEnergyPlatform\n",
    "<br><br>\n",
    "\n",
    "# MaStR Data Cleaning\n",
    "Repository: https://github.com/OpenEnergyPlatform/data-preprocessing/tree/master/data-import/bnetza_mastr\n",
    "\n",
    "Please report bugs and improvements here: https://github.com/OpenEnergyPlatform/data-preprocessing/issues <br>\n",
    "How to get started with Jupyter Notebooks can be found here: https://github.com/OpenEnergyPlatform/oeplatform/wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__copyright__ = \"Bauhaus Luftfahrt e.V.\"\n",
    "__license__   = \"GNU Affero General Public License Version 3 (AGPL-3.0)\"\n",
    "__url__       = \"https://github.com/openego/data_processing/blob/master/LICENSE\"\n",
    "__author__    = \"Benjamin W. Portner\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Load-data\" data-toc-modified-id=\"Load-data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Load data</a></span></li><li><span><a href=\"#Drop-duplicates\" data-toc-modified-id=\"Drop-duplicates-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Drop duplicates</a></span></li><li><span><a href=\"#Drop-unlocated\" data-toc-modified-id=\"Drop-unlocated-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Drop unlocated</a></span></li><li><span><a href=\"#Drop-incorrectly-located\" data-toc-modified-id=\"Drop-incorrectly-located-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Drop incorrectly located</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First off, imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.geometry import Point\n",
    "\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, load the datasets for hydro, wind and biomass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = '1.4'\n",
    "\n",
    "fn_wind = f'bnetza_mastr_rli_v{version}_wind'\n",
    "df_wind = pd.read_csv(f'data/OEP/bnetza_mastr_power-units_rli_v{version}/{fn_wind}.csv', \n",
    "                      encoding='utf8', sep=';', parse_dates=[\"Inbetriebnahmedatum\"], dtype={\"Postleitzahl\":str})\n",
    "\n",
    "fn_hydro = f'bnetza_mastr_rli_v{version}_hydro'\n",
    "df_hydro = pd.read_csv(f'data/OEP/bnetza_mastr_power-units_rli_v{version}/{fn_hydro}.csv', \n",
    "                       encoding='utf8', sep=';', parse_dates=[\"Inbetriebnahmedatum\"], dtype={\"Postleitzahl\":str})\n",
    "\n",
    "fn_biomass = f'bnetza_mastr_rli_v{version}_biomass'\n",
    "df_biomass = pd.read_csv(f'data/OEP/bnetza_mastr_power-units_rli_v{version}/{fn_biomass}.csv', \n",
    "                         encoding='utf8', sep=';', parse_dates=[\"Inbetriebnahmedatum\"], dtype={\"Postleitzahl\":str})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge them into one DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_wind.append(df_hydro, ignore_index=True, sort=False).append(df_biomass, ignore_index=True, sort=False)\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some reason, there is an unnamed column. Let's drop it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop duplicates\n",
    "\n",
    "Next, let's see if all the entries are unique. Dropping duplicates does not work on this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_before = len(df_all)\n",
    "len_after = len(df_all.drop_duplicates())\n",
    "\n",
    "len_before, len_before == len_after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, there are quite a few entries that are basically identical: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[df_all.duplicated(subset=\"EinheitMastrNummer\", keep=False)].sort_values(by=\"EinheitMastrNummer\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why were these not dropped before? Because the dataset contains a timestamp that documents the time of download for each entry. Naturally, that timestep is unique for each entry. Let's drop it and repeat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create one dataframe with all duplicated entries\n",
    "has_double = df_all.drop(columns=[\"timestamp_e\"]).duplicated(keep=False)\n",
    "df_duplicated = df_all[has_double].copy().sort_values(by=\"EinheitMastrNummer\").reset_index(drop=True)\n",
    "\n",
    "# create one dataframe with only unique entries\n",
    "is_unique = ~df_all.drop(columns=[\"timestamp_e\"]).duplicated(keep=\"first\")\n",
    "df_unique = df_all[is_unique].copy().sort_values(by=\"EinheitMastrNummer\").reset_index(drop=True)\n",
    "\n",
    "# compare sizes\n",
    "len(df_all), len(df_duplicated), len(df_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 65,133 unique entries. That is 6,004 less than in the merged dataset. There are 9,381 entries which have at least one double."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output direction if it does not already exist\n",
    "outdir = './output'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "\n",
    "# export\n",
    "df_duplicated.to_csv(\"output/OEP_0_duplicated.csv\", index=False)\n",
    "df_unique.to_csv(\"output/OEP_0_unique.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop unlocated\n",
    "\n",
    "Next, I will remove all entries which do not have coordinates associated with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlocated_index = df_unique[[\"Laengengrad\", \"Breitengrad\"]].isna().any(axis=1)\n",
    "df_unlocated = df_unique[unlocated_index].copy().reset_index(drop=True)\n",
    "df_located = df_unique[~unlocated_index].copy().reset_index(drop=True)\n",
    "len(df_unique), len(df_located), len(df_unlocated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Little more than half of the entries have no coordinates. Export:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unlocated.to_csv(\"output/OEP_1_unlocated.csv\", index=False)\n",
    "df_located.to_csv(\"output/OEP_1_located.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop incorrectly located\n",
    "\n",
    "Some entries have coordinates outside Germany. Some of these are off-shore wind turbines. However, there are entries which have addresses in Bayern or Niedersachsen but are located in Italy, and even Africa. Also, some entries lie within Germany but in the wrong Bundesland. I will identify and remove these.\n",
    "\n",
    "\n",
    "First, load the shape files. They contain polygons describing the boundaries of the Bundesländer, and of the German exclusive economic zones in the Baltic sea and in the North Sea:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_bld = gpd.read_file(r\"data\\shapefiles_germany\\BKG\\vg2500_bld.shp\")\n",
    "gdf_baltic = gpd.read_file(r\"data\\shapefiles_germany\\marineregions.org\\DE_baltic_sea\\eez_iho.shp\")\n",
    "gdf_north_sea = gpd.read_file(r\"data\\shapefiles_germany\\marineregions.org\\DE_north_sea\\eez_iho.shp\")\n",
    "\n",
    "gdf_bld.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nomenclature to describe the Bundesländer is different from the OEP standard. Fix that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_map = {\n",
    "    'Thüringen': 'Thueringen',\n",
    "    'Sachsen-Anhalt': 'SachsenAnhalt',\n",
    "    'Mecklenburg-Vorpommern': 'MecklenburgVorpommern',\n",
    "    'Nordrhein-Westfalen': 'NordrheinWestfalen',\n",
    "    'Rheinland-Pfalz': 'RheinlandPfalz',\n",
    "    'Schleswig-Holstein': 'SchleswigHolstein',\n",
    "    'Baden-Württemberg': 'BadenWuerttemberg',\n",
    "}\n",
    "gdf_bld[\"GEN\"] = gdf_bld[\"GEN\"].replace(rename_map)\n",
    "gdf_baltic[\"GEN\"] = \"AusschliesslicheWirtschaftszone\"\n",
    "gdf_north_sea[\"GEN\"] = \"AusschliesslicheWirtschaftszone\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the three GeoDataFrames into one for easier handling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_bld_eez = gdf_bld.\\\n",
    "    append(gdf_baltic, ignore_index=True, sort=False).\\\n",
    "    append(gdf_north_sea, ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extend the polygons slightly to make sure that points close to their edge will be correctly identified as within:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = 0.01\n",
    "gdf_bld_eez[\"geometry\"] = gdf_bld_eez.buffer(buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I want to check for all entries if their coordinates are really located in the Bundesland specified in the entry. First, remove entries without Bundesland:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_bld = df_located[df_located[\"Bundesland\"].isna()].copy().reset_index(drop=True)\n",
    "df_bld = df_located[~df_located[\"Bundesland\"].isna()].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check if their coordinates are correct, I first need convert all entries to a GeoDataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id_bld_coord = df_bld[[\"EinheitMastrNummer\", \"Bundesland\", \"Laengengrad\", \"Breitengrad\"]]\n",
    "points = [Point(xy) for xy in zip(df_id_bld_coord[\"Laengengrad\"], df_id_bld_coord[\"Breitengrad\"])]\n",
    "crs = {'init': 'epsg:4326'}\n",
    "gdf_points = gpd.GeoDataFrame(df_id_bld_coord[[\"EinheitMastrNummer\", \"Bundesland\"]], crs=crs, geometry=points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's check. By default, all entries are tagged as incorrectly located:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bld[\"correct_bld\"] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate over the Bundesländer. Check for all entries of the Bundesland whether their coordinates are in the polygon defined in the shape file. If yes, tag them as correctly located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bld in df_bld[\"Bundesland\"].unique():\n",
    "\n",
    "    # get points which are supposedly in the Bundesland\n",
    "    gdf_points_bld = gdf_points[gdf_points[\"Bundesland\"] == bld]\n",
    "\n",
    "    # find all points which really are in the Bundesland\n",
    "    points_in_bld = gpd.sjoin(gdf_points_bld, gdf_bld_eez[gdf_bld_eez[\"GEN\"]==bld], how=\"right\", op=\"within\")\n",
    "\n",
    "    # tag those as correctly located\n",
    "    df_bld.loc[\n",
    "        df_bld[\"EinheitMastrNummer\"].isin(points_in_bld[\"EinheitMastrNummer\"]),\n",
    "        \"correct_bld\"\n",
    "    ] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate correctly located entries from incorrectly located entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_correct_lctn = df_bld[df_bld[\"correct_bld\"]].copy().reset_index(drop=True)\n",
    "df_incorrect_lctn = df_bld[~df_bld[\"correct_bld\"]].copy().reset_index(drop=True)\n",
    "len(df_bld), len(df_correct_lctn), len(df_incorrect_lctn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the 32,259 entries which have Bundesland and coordinates specified, 31,685 are located correctly. 574 are located incorrectly.\n",
    "\n",
    "Export csv's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_bld.to_csv(\"output/OEP_2_no_bld.csv\", index=False)\n",
    "df_correct_lctn.to_csv(\"output/OEP_2_correct_lctn.csv\", index=False)\n",
    "df_incorrect_lctn.to_csv(\"output/OEP_2_incorrect_lctn.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also export interactive maps of correctly and incorrectly located entries. These maps are zoomable and panable. When hovering over a point on the map, the entry's name, address, type, and gross output is shown as a tooltip. Also, clicking on legend entries will show/hide the corresponding points. All the plotting logic is contained in the function \"plotPowerPlants\" of the \"helpers\" module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correct_lctn = plotPowerPlants(df_correct_lctn)\n",
    "plot_incorrect_lctn = plotPowerPlants(df_incorrect_lctn)\n",
    "\n",
    "# export as html\n",
    "gv.renderer(\"bokeh\").save(plot_correct_lctn, \"output/OEP_2_correct_lctn\")\n",
    "gv.renderer(\"bokeh\").save(plot_incorrect_lctn, \"output/OEP_2_incorrect_lctn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the outliers were identified correctly. Now, what can we do about the wrongly located entries? Maybe we can use data from other sources to get their coordinates. I will describe this in the [next notebook](OEP_MaStR_supplement_coords.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
